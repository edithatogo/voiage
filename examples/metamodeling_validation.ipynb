{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metamodeling Validation Notebook\n",
    "\n",
    "This notebook validates the metamodeling functionality in voiage by demonstrating:\n",
    "1. Basic usage of different metamodels\n",
    "2. Cross-validation capabilities\n",
    "3. Model comparison functionality\n",
    "4. Diagnostic calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the voiage package to the path\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), '.'))\n",
    "\n",
    "from voiage.schema import ParameterSet\n",
    "from voiage.metamodels import (\n",
    "    RandomForestMetamodel,\n",
    "    GAMMetamodel,\n",
    "    BARTMetamodel,\n",
    "    calculate_diagnostics,\n",
    "    cross_validate,\n",
    "    compare_metamodels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data for demonstration\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create sample parameters\n",
    "n_samples = 100\n",
    "param1 = np.random.rand(n_samples)\n",
    "param2 = np.random.rand(n_samples)\n",
    "\n",
    "# Create a simple target function with some noise\n",
    "# y = 2*x1 + 3*x2 + x1*x2 + noise\n",
    "y = 2 * param1 + 3 * param2 + param1 * param2 + 0.1 * np.random.randn(n_samples)\n",
    "\n",
    "# Create ParameterSet\n",
    "data = {\n",
    "    \"param1\": (\"n_samples\", param1),\n",
    "    \"param2\": (\"n_samples\", param2),\n",
    "}\n",
    "x = ParameterSet(dataset=xr.Dataset(data))\n",
    "\n",
    "print(f\"Created sample data with {len(y)} samples and {len(x.parameter_names)} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Testing RandomForest Metamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RandomForest\n",
    "print(\"1. Testing RandomForest Metamodel:\")\n",
    "rf_model = RandomForestMetamodel(n_estimators=50, random_state=42)\n",
    "rf_model.fit(x, y)\n",
    "rf_pred = rf_model.predict(x)\n",
    "print(f\"   Prediction shape: {rf_pred.shape}\")\n",
    "print(f\"   R² score: {rf_model.score(x, y):.4f}\")\n",
    "print(f\"   RMSE: {rf_model.rmse(x, y):.4f}\")\n",
    "\n",
    "# Test diagnostics\n",
    "rf_diagnostics = calculate_diagnostics(rf_model, x, y)\n",
    "print(f\"   Diagnostics: R²={rf_diagnostics['r2']:.4f}, RMSE={rf_diagnostics['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing GAM Metamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GAM (if available)\n",
    "print(\"\\n2. Testing GAM Metamodel:\")\n",
    "try:\n",
    "    gam_model = GAMMetamodel(n_splines=10)\n",
    "    gam_model.fit(x, y)\n",
    "    gam_pred = gam_model.predict(x)\n",
    "    print(f\"   Prediction shape: {gam_pred.shape}\")\n",
    "    print(f\"   R² score: {gam_model.score(x, y):.4f}\")\n",
    "    print(f\"   RMSE: {gam_model.rmse(x, y):.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"   GAM not available or failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing BART Metamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test BART (if available)\n",
    "print(\"\\n3. Testing BART Metamodel:\")\n",
    "try:\n",
    "    # Use smaller sample for BART to keep it fast\n",
    "    x_small = ParameterSet(\n",
    "        dataset=xr.Dataset({\n",
    "            \"param1\": (\"n_samples\", x.parameters[\"param1\"][:50]),\n",
    "            \"param2\": (\"n_samples\", x.parameters[\"param2\"][:50]),\n",
    "        })\n",
    "    )\n",
    "    y_small = y[:50]\n",
    "    \n",
    "    bart_model = BARTMetamodel(num_trees=20)\n",
    "    bart_model.fit(x_small, y_small)\n",
    "    bart_pred = bart_model.predict(x_small)\n",
    "    print(f\"   Prediction shape: {bart_pred.shape}\")\n",
    "    print(f\"   R² score: {bart_model.score(x_small, y_small):.4f}\")\n",
    "    print(f\"   RMSE: {bart_model.rmse(x_small, y_small):.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"   BART not available or failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-validation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cross-validation\n",
    "print(\"\\n4. Cross-validation example:\")\n",
    "try:\n",
    "    cv_results = cross_validate(RandomForestMetamodel, x, y, cv_folds=3)\n",
    "    print(f\"   Cross-validation R²: {cv_results['cv_r2_mean']:.4f} ± {cv_results['cv_r2_std']:.4f}\")\n",
    "    print(f\"   Cross-validation RMSE: {cv_results['cv_rmse_mean']:.4f} ± {cv_results['cv_rmse_std']:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Cross-validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model comparison\n",
    "print(\"\\n5. Model comparison example:\")\n",
    "try:\n",
    "    models = [RandomForestMetamodel]\n",
    "    comparison = compare_metamodels(models, x, y, cv_folds=2)\n",
    "    for model_name, results in comparison.items():\n",
    "        if \"error\" not in results:\n",
    "            print(f\"   {model_name}: R²={results['cv_r2_mean']:.4f} ± {results['cv_r2_std']:.4f}\")\n",
    "        else:\n",
    "            print(f\"   {model_name}: Error - {results['error']}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Model comparison failed: {e}\")\n",
    "\n",
    "print(\"\\nValidation notebook completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}