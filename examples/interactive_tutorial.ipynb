{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Tutorial: Advanced Value of Information Analysis with voiage\n",
    "\n",
    "This tutorial demonstrates the advanced features of the voiage library for Value of Information (VOI) analysis, including:\n",
    "\n",
    "- Streaming data support for continuous VOI updates\n",
    "- Incremental computation for large datasets\n",
    "- Caching mechanisms for repeated calculations\n",
    "- Healthcare-specific utilities (QALY calculations)\n",
    "- Environmental impact assessment tools\n",
    "- Financial risk analysis components\n",
    "- Parallel processing for Monte Carlo simulations\n",
    "- GPU acceleration support\n",
    "- Memory optimization for large-scale analyses\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Import voiage components\n",
    "from voiage.analysis import DecisionAnalysis\n",
    "from voiage.schema import ValueArray, ParameterSet\n",
    "from voiage.healthcare.utilities import calculate_qaly, discount_qaly\n",
    "from voiage.environmental.impact_assessment import calculate_carbon_footprint, monetize_environmental_impacts\n",
    "from voiage.financial.risk_analysis import calculate_value_at_risk, calculate_sharpe_ratio\n",
    "from voiage.parallel.monte_carlo import parallel_monte_carlo_simulation\n",
    "from voiage.core.gpu_acceleration import is_gpu_available, GPUAcceleratedEVPI\n",
    "from voiage.core.memory_optimization import MemoryOptimizer, memory_efficient_evpi_computation\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "print(f\"GPU available: {is_gpu_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic VOI Analysis\n",
    "\n",
    "Let's start with a basic VOI analysis to establish our baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample net benefit data\n",
    "# 1000 PSA samples, 3 decision strategies\n",
    "net_benefits = np.random.randn(1000, 3) * 1000 + 5000\n",
    "value_array = ValueArray.from_numpy(net_benefits)\n",
    "\n",
    "# Create basic decision analysis\n",
    "analysis = DecisionAnalysis(value_array)\n",
    "\n",
    "# Calculate EVPI\n",
    "evpi_result = analysis.evpi()\n",
    "print(f\"Basic EVPI: {evpi_result:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Streaming Data Support\n",
    "\n",
    "Now let's demonstrate streaming data support for continuous VOI updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decision analysis with streaming support\n",
    "streaming_analysis = DecisionAnalysis(value_array, streaming_window_size=500)\n",
    "\n",
    "# Get streaming EVPI generator\n",
    "evpi_generator = streaming_analysis.streaming_evpi()\n",
    "\n",
    "# Simulate receiving new data over time\n",
    "streaming_evpi_values = []\n",
    "for i in range(5):\n",
    "    # Generate new data\n",
    "    new_data = np.random.randn(200, 3) * 1000 + 5000\n",
    "    new_value_array = ValueArray.from_numpy(new_data)\n",
    "    \n",
    "    # Update analysis with new data\n",
    "    streaming_analysis.update_with_new_data(new_value_array)\n",
    "    \n",
    "    # Get updated EVPI\n",
    "    evpi_value = next(evpi_generator)\n",
    "    streaming_evpi_values.append(evpi_value)\n",
    "    \n",
    "    print(f\"EVPI after update {i+1}: {evpi_value:.2f}\")\n",
    "\n",
    "# Plot streaming EVPI values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 6), streaming_evpi_values, marker='o')\n",
    "plt.xlabel('Update Number')\n",
    "plt.ylabel('EVPI')\n",
    "plt.title('Streaming EVPI Updates')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Incremental Computation for Large Datasets\n",
    "\n",
    "Let's demonstrate incremental computation with a large dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a large dataset\n",
    "large_net_benefits = np.random.randn(50000, 3) * 1000 + 5000\n",
    "large_value_array = ValueArray.from_numpy(large_net_benefits)\n",
    "\n",
    "# Create analysis\n",
    "large_analysis = DecisionAnalysis(large_value_array)\n",
    "\n",
    "# Time regular computation\n",
    "start_time = time.time()\n",
    "regular_evpi = large_analysis.evpi()\n",
    "regular_time = time.time() - start_time\n",
    "\n",
    "# Time incremental computation\n",
    "start_time = time.time()\n",
    "incremental_evpi = large_analysis.evpi(chunk_size=5000)\n",
    "incremental_time = time.time() - start_time\n",
    "\n",
    "print(f\"Regular EVPI: {regular_evpi:.2f} (Time: {regular_time:.4f}s)\")\n",
    "print(f\"Incremental EVPI: {incremental_evpi:.2f} (Time: {incremental_time:.4f}s)\")\n",
    "print(f\"Difference: {abs(regular_evpi - incremental_evpi):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Caching Mechanisms\n",
    "\n",
    "Let's demonstrate caching for repeated calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create analysis with caching enabled\n",
    "cached_analysis = DecisionAnalysis(value_array, enable_caching=True)\n",
    "\n",
    "# First calculation (no cache)\n",
    "start_time = time.time()\n",
    "result1 = cached_analysis.evpi()\n",
    "time1 = time.time() - start_time\n",
    "\n",
    "# Second calculation (uses cache)\n",
    "start_time = time.time()\n",
    "result2 = cached_analysis.evpi()\n",
    "time2 = time.time() - start_time\n",
    "\n",
    "print(f\"First calculation: {result1:.2f} (Time: {time1:.6f}s)\")\n",
    "print(f\"Second calculation: {result2:.2f} (Time: {time2:.6f}s)\")\n",
    "print(f\"Speedup: {time1/time2:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Healthcare-Specific Utilities\n",
    "\n",
    "Let's demonstrate healthcare-specific utilities like QALY calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example QALY calculation\n",
    "time_points = np.array([0, 1, 2, 3, 4, 5])  # Years\n",
    "qaly_values = np.array([0.8, 0.75, 0.7, 0.65, 0.6, 0.55])  # QALY weights\n",
    "costs = np.array([10000, 8000, 7000, 6000, 5000, 4000])  # Costs per year\n",
    "\n",
    "# Calculate total QALYs\n",
    "total_qaly = calculate_qaly(time_points, qaly_values)\n",
    "print(f\"Total QALYs: {total_qaly:.2f}\")\n",
    "\n",
    "# Apply discounting\n",
    "discount_rate = 0.03  # 3% discount rate\n",
    "discounted_qaly = discount_qaly(time_points, qaly_values, discount_rate)\n",
    "print(f\"Discounted QALYs: {discounted_qaly:.2f}\")\n",
    "\n",
    "# Plot QALY trajectory\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_points, qaly_values, marker='o')\n",
    "plt.xlabel('Time (years)')\n",
    "plt.ylabel('QALY')\n",
    "plt.title('QALY Trajectory Over Time')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Environmental Impact Assessment\n",
    "\n",
    "Let's demonstrate environmental impact assessment tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example carbon footprint calculation\n",
    "energy_consumption_kwh = 10000  # kWh\n",
    "carbon_intensity = 0.5  # kg CO2/kWh\n",
    "\n",
    "carbon_footprint = calculate_carbon_footprint(energy_consumption_kwh, carbon_intensity)\n",
    "print(f\"Carbon footprint: {carbon_footprint:.2f} kg CO2\")\n",
    "\n",
    "# Monetize environmental impacts\n",
    "social_cost_of_carbon = 50  # $/ton CO2\n",
    "monetized_impact = monetize_environmental_impacts(carbon_footprint/1000, social_cost_of_carbon)\n",
    "print(f\"Monetized environmental impact: ${monetized_impact:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Financial Risk Analysis\n",
    "\n",
    "Let's demonstrate financial risk analysis components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example financial returns data\n",
    "returns = np.random.randn(1000) * 0.02 + 0.005  # Daily returns\n",
    "\n",
    "# Calculate Value at Risk (VaR)\n",
    "confidence_level = 0.95\n",
    "var_result = calculate_value_at_risk(returns, confidence_level)\n",
    "print(f\"Value at Risk (95% confidence): {var_result:.4f}\")\n",
    "\n",
    "# Calculate Sharpe ratio\n",
    "risk_free_rate = 0.0001  # Daily risk-free rate\n",
    "sharpe_result = calculate_sharpe_ratio(returns, risk_free_rate)\n",
    "print(f\"Sharpe ratio: {sharpe_result:.4f}\")\n",
    "\n",
    # Plot returns distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(returns, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(var_result, color='red', linestyle='--', label=f'VaR ({confidence_level:.0%})')\n",
    "plt.xlabel('Returns')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Financial Returns')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Parallel Processing for Monte Carlo Simulations\n",
    "\n",
    "Let's demonstrate parallel processing capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple model function for demonstration\n",
    "def simple_model_func(params):\n",
    "    # Extract parameters\n",
    "    if hasattr(params, 'parameters'):\n",
    "        mean_treatment = params.parameters.get('mean_treatment', np.array([0.0]))\n",
    "        mean_control = params.parameters.get('mean_control', np.array([0.0]))\n",
    "    else:\n",
    "        mean_treatment = params.get('mean_treatment', np.array([0.0]))\n",
    "        mean_control = params.get('mean_control', np.array([0.0]))\n",
    "    \n",
    "    # Calculate net benefits\n",
    "    nb_treatment = mean_treatment\n",
    "    nb_control = mean_control\n",
    "    \n",
    "    # Stack to create ValueArray-compatible structure\n",
    "    nb_values = np.column_stack([nb_control, nb_treatment]).astype(np.float64)\n",
    "    return ValueArray.from_numpy(nb_values)\n",
    "\n",
    "# Create parameter set for Monte Carlo simulation\n",
    "params_data = {\n",
    "    'mean_treatment': np.random.normal(1.0, 0.2, 1000),\n",
    "    'mean_control': np.random.normal(0.5, 0.1, 1000),\n",
    "}\n",
    "parameter_set = ParameterSet.from_numpy_or_dict(params_data)\n",
    "\n",
    "# Run parallel Monte Carlo simulation\n",
    "start_time = time.time()\n",
    "parallel_result = parallel_monte_carlo_simulation(\n",
    "    model_func=simple_model_func,\n",
    "    psa_prior=parameter_set,\n",
    "    trial_design=None,  # Simplified for demonstration\n",
    "    n_simulations=1000,\n",
    "    n_workers=4,\n",
    "    use_processes=True\n",
    ")\n",
    "parallel_time = time.time() - start_time\n",
    "\n",
    "print(f\"Parallel Monte Carlo result: {parallel_result:.4f}\")\n",
    "print(f\"Computation time: {parallel_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. GPU Acceleration Support\n",
    "\n",
    "Let's demonstrate GPU acceleration if available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_gpu_available():\n",
    "    # Create GPU-accelerated EVPI calculator\n",
    "    gpu_evpi = GPUAcceleratedEVPI()\n",
    "    \n",
    "    # Create sample data\n",
    "    gpu_net_benefits = np.random.randn(10000, 3) * 1000 + 5000\n",
    "    \n",
    "    # Time CPU computation\n",
    "    start_time = time.time()\n",
    "    cpu_evpi = analysis.evpi()\n",
    "    cpu_time = time.time() - start_time\n",
    "    \n",
    "    # Time GPU computation\n",
    "    start_time = time.time()\n",
    "    gpu_evpi_result = gpu_evpi.calculate_evpi(gpu_net_benefits)\n",
    "    gpu_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"CPU EVPI: {cpu_evpi:.2f} (Time: {cpu_time:.6f}s)\")\n",
    "    print(f\"GPU EVPI: {gpu_evpi_result:.2f} (Time: {gpu_time:.6f}s)\")\n",
    "    print(f\"Speedup: {cpu_time/gpu_time:.2f}x\")\n",
    "else:\n",
    "    print(\"GPU not available. Skipping GPU acceleration demonstration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Memory Optimization for Large-Scale Analyses\n",
    "\n",
    "Let's demonstrate memory optimization techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a very large dataset\n",
    "huge_net_benefits = np.random.randn(100000, 3) * 1000 + 5000\n",
    "\n",
    "# Create memory optimizer\n",
    "memory_optimizer = MemoryOptimizer()\n",
    "\n",
    "# Check available memory\n",
    "available_memory = memory_optimizer.get_available_memory()\n",
    "print(f\"Available memory: {available_memory / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Estimate memory usage of our data\n",
    "data_memory = memory_optimizer.estimate_memory_usage(huge_net_benefits)\n",
    "print(f\"Data memory usage: {data_memory / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Use memory-efficient EVPI computation\n",
    "start_time = time.time()\n",
    "efficient_evpi = memory_efficient_evpi_computation(huge_net_benefits, chunk_size=10000)\n",
    "efficient_time = time.time() - start_time\n",
    "\n",
    "print(f\"Memory-efficient EVPI: {efficient_evpi:.2f}\")\n",
    "print(f\"Computation time: {efficient_time:.4f}s\")\n",
    "\n",
    "# Force garbage collection\n",
    "memory_optimizer.force_garbage_collection()\n",
    "print(\"Garbage collection completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial has demonstrated the advanced features of the voiage library:\n",
    "\n",
    "1. **Streaming Data Support**: Continuous VOI updates as new data arrives\n",
    "2. **Incremental Computation**: Efficient processing of large datasets\n",
    "3. **Caching Mechanisms**: Performance optimization for repeated calculations\n",
    "4. **Healthcare Utilities**: QALY calculations and discounting\n",
    "5. **Environmental Tools**: Carbon footprint and monetization calculations\n",
    "6. **Financial Risk Analysis**: VaR and Sharpe ratio calculations\n",
    "7. **Parallel Processing**: Multi-core Monte Carlo simulations\n",
    "8. **GPU Acceleration**: Hardware-accelerated computations\n",
    "9. **Memory Optimization**: Efficient handling of large-scale analyses\n",
    "\n",
    "These features make voiage a powerful tool for comprehensive Value of Information analysis across multiple domains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}